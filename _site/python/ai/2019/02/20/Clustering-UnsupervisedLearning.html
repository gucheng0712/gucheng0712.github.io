<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1 maximum-scale=1; minimum-scale=1; user-scalable=no;"> <meta name="author" content="ChengGu"> <meta name="baseurl" content=""> <title> Suzuka Site|Clustering - Unsupervised Learning(ML) </title> <!-- favicon --> <link rel="shortcut icon" href="/static/assets/img/favicon.ico"> <!-- Main CSS --> <link href="/static/assets/app-20180125.min.css" rel="stylesheet"> <link href="/static/css/custom.css" rel="stylesheet"> <!-- Main Scripts --> <script src="/static/assets/app-20180125.min.js"></script> <script src="/static/assets/blog-20180125.min.js"></script> <!-- Google AdSense --> <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> <script> (adsbygoogle = window.adsbygoogle || []).push({ google_ad_client: "ca-pub-6196184668650108", enable_page_level_ads: true }); </script> </head> <body id="page-top" class="landing-page"> <div class="search-tool" style="position: fixed; top: 0px ; bottom: 0px; left: 0px; right: 0px; opacity: 0.95; background-color: #111111; z-index: 9999; display: none;"> <input type="text" class="form-control search-content" id="search-content" style="position: fixed; top: 60px" placeholder="Search Blog"> <div style="position: fixed; top: 16px; right: 16px; z-index: 9999;"> <img src="/static/assets/img/search/cb-close.png" id="close-btn"/> </div> </div> <div style="position: fixed; right: 16px; bottom: 20px; z-index: 9999;"> <img src="/static/assets/img/search/cb-search.png" id="search-btn" title="Double click Ctrl"/> </div> <div class="navbar-wrapper"> <nav class="navbar navbar-default navbar-fixed-top" role="navigation"> <div class="container"> <div class="navbar-header page-scroll"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/">Suzuka Site</a> </div> <div id="navbar" class="navbar-collapse collapse"> <ul class="nav navbar-nav navbar-right"> <li><a class="page-scroll" href="blog/"></a></li> <li> <a class="page-scroll" href="/blog/">Blog</a></li> <li> <a class="page-scroll" href="/unity/">Unity</a></li> <li> <a class="page-scroll" href="/ai/">AI</a></li> <li> <a class="page-scroll" href="/cg/">CG</a></li> <li> <a class="page-scroll" href="/math/">Math</a></li> <li> <a class="page-scroll" href="/data structure/">Data Structure</a></li> <li> <a class="page-scroll" href="/csharp/">C#</a></li> <li> <a class="page-scroll" href="/python/">Python</a></li> <li> <a class="page-scroll" href="/javascript/">JavaScript</a></li> <li> <a class="page-scroll" href="/game dev/">Game Dev</a></li> </ul> </div> </div> </nav> </div> <!--<link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css'>--> <!--<link rel="stylesheet" href="static/css/carousel_style.css">--> <!--<script src="static/js/carousel.js"></script>--> <div id="carouselHacked" class="carousel slide carousel-fade" data-ride="carousel"> <div class="carousel-inner" role="listbox"> <div class="item active"> <!-- Set background for slide in css --> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_1.jpg);" title="first banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_2.jpg);" title=""> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_3.jpg);" title="third banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_4.jpg);" title="fourth banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_5.jpg);" title="fifth banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_6.jpg);" title="sixth banner image"> </div> </div> </div> <!-- Controls --> <a class="left carousel-control" href="#carouselHacked" role="button" data-slide="prev"> <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span> <span class="sr-only">Previous</span> </a> <a class="right carousel-control" href="#carouselHacked" role="button" data-slide="next"> <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span> <span class="sr-only">Next</span> </a> </div> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true } }); </script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <div class="wrapper wrapper-content animated fadeInRight article"> <div class="row"> <div class="col-lg-10 col-lg-offset-1"> <div class="ibox"> <div class="ibox-content"> <div class="pull-right"> <a class="btn btn-white btn-xs" href="/python">Python</a> <a class="btn btn-white btn-xs" href="/ai">Ai</a> </div> <div class="text-center article-title"> <span class="text-muted"><i class="fa fa-clock-o"></i> 20 Feb 2019</span> <h1> Clustering - Unsupervised Learning(ML) </h1> </div> <h1 id="supervised-learning-vs-unsupervised-learning"><strong>Supervised Learning Vs Unsupervised Learning</strong></h1> <p align="center"> <img src="/static/assets/img/blog/Supervised Learning Vs Unsupervised Learning.jpeg" width="30%" /> </p> <p>To <code class="highlighter-rouge">determine</code> a machine learning whether is supervised learning <code class="highlighter-rouge">or</code> unsupervised learning, basicly depends on if the input data(features) has <code class="highlighter-rouge">label</code>, such as regression and classification. <code class="highlighter-rouge">Supervised Learning</code> is defined as input data(features) with labels. <code class="highlighter-rouge">Unsupervised Learning</code> is defined as input data without labels, such as clustering, and dimensional reduction.</p> <blockquote> <p><code class="highlighter-rouge">“Because we don't give it the answer, it's unsupervised learning”</code></p> </blockquote> <hr /> <h2 id="what-is-clustering"><strong>What is Clustering?</strong></h2> <p align="center"> <img src="/static/assets/img/blog/clustering.png" width="50%" /></p> <p>A common case of unsupervised learning is <code class="highlighter-rouge">clustering</code>, a process in which data is assigned to a number of discrete groups. Clustering is a little bit similiar to the classification but it <code class="highlighter-rouge">doesn't</code> have label, which means, it <code class="highlighter-rouge">doesn't</code> need to care about what a certain <code class="highlighter-rouge">category</code> is, the <code class="highlighter-rouge">goal</code> is just to gather similar things together. Therefore, clustering algorithm often only needs to know<code class="highlighter-rouge"> how to calculate the similarity</code> to start working, so it normally <code class="highlighter-rouge">doesn't</code> need to use training data for learning.</p> <hr /> <h2 id="k-means-algorithm"><strong>K-Means Algorithm</strong></h2> <p align="center"> <img src="/static/assets/img/blog/Animation_of_k-means_clustering.gif" width="50%" /></p> <p><code class="highlighter-rouge">k-Means</code> is a simple and popular algorithm that searches for a <code class="highlighter-rouge">predetermined</code> number of clusters within an <code class="highlighter-rouge">unlabeled dataset</code> by following the steps outlined below:</p> <blockquote> <p><strong>Pseudocode:</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">randomly</span> <span class="n">choose</span> <span class="n">k</span> <span class="n">examles</span> <span class="k">as</span> <span class="n">initial</span> <span class="n">centroids</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">create</span> <span class="n">k</span> <span class="n">clusters</span> <span class="n">by</span> <span class="n">assigning</span> <span class="n">each</span> <span class="n">example</span> <span class="n">to</span> <span class="n">closest</span> <span class="n">centroid</span>
    <span class="n">compute</span> <span class="n">k</span> <span class="n">new</span> <span class="n">centroids</span> <span class="n">by</span> <span class="n">averaging</span> <span class="n">examples</span> <span class="ow">in</span> <span class="n">each</span> <span class="n">cluster</span>
    <span class="k">if</span> <span class="n">centroids</span> <span class="n">don</span><span class="s">'t change:</span><span class="err">
</span><span class="s">        break</span><span class="err">
</span></code></pre></div></div> <blockquote> <p><strong>Code Example with Scrit-Learn</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c"># input data, containing 4 blobs</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.40</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c"># initialize and train K-means model with the input data to 4 regions</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c"># predict the results </span>
<span class="n">y_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c"># assign the predicted results into the color element to visualize</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_kmeans</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">)</span>

<span class="c"># plot the center of each region</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <blockquote> <p><strong>Output:</strong></p> </blockquote> <p><img src="/static/assets/img/blog/kmeanexample.png" width="30%" /></p> <hr /> <h2 id="mean-shift-algorithm"><strong>Mean-Shift Algorithm</strong></h2> <p align="center"> <img src="/static/assets/img/blog/meanshift.gif" width="50%" /></p> <p><code class="highlighter-rouge">Meanshift</code> looks very similiar to K-Means, they both move the point closer to the cluster <code class="highlighter-rouge">centroids</code>. However, the difference between them is that Meanshift <code class="highlighter-rouge">doesn't</code> require to specify the <code class="highlighter-rouge">number of clusters</code>, but it is <code class="highlighter-rouge">slower</code> than the K-Means in terms of runtime complexity!</p> <blockquote> <p><strong>Pseudocode:</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span> <span class="ow">not</span> <span class="n">converges</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">each</span> <span class="n">data</span> <span class="n">point</span><span class="p">:</span>
        <span class="n">fix</span> <span class="n">a</span> <span class="n">data_range</span>
    <span class="n">calculate</span> <span class="n">the</span> <span class="n">data</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">data_range</span>
    <span class="n">Move</span> <span class="n">the</span> <span class="n">data_range</span> <span class="n">to</span> <span class="n">the</span> <span class="n">new</span> <span class="n">center</span>
</code></pre></div></div> <blockquote> <p><strong>Code Example with Scrit-Learn</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MeanShift</span><span class="p">,</span> <span class="n">estimate_bandwidth</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c"># input data, containing 4 blobs </span>
<span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.40</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="c"># Estimate the bandwidth of X</span>
<span class="s">'''
# Bandwidth affects the overall convergence speed and the final number of clusters
# If the bandwidth is small, it might results in too many clusters, 
# where as if the value is large, then it will merge distinct clusters.
'''</span>
<span class="s">'''
The quantile parameter impacts how the bandwidth is estimated.
higher value for quantile will increase the estimated bandwidth, 
resulting in a lesser number of clusters
'''</span>
<span class="n">bandwidth_X</span> <span class="o">=</span> <span class="n">estimate_bandwidth</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">n_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="c"># Initialize and train the model using the estimated bandwidth</span>
<span class="s">'''
bin_seeding : boolean, optional
If true, initial kernel locations are not locations of all points, 
but rather the location of the discretized version of points, 
where points are binned onto a grid whose coarseness corresponds to the bandwidth. 
Setting this option to True will speed up the algorithm because fewer seeds will be initialized. 
'''</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MeanShift</span><span class="p">(</span><span class="n">bandwidth</span><span class="o">=</span><span class="n">bandwidth_X</span><span class="p">,</span><span class="n">bin_seeding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_meanshit</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_meanshit</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">)</span>

<span class="c"># Extract the centers of clusters</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Centers of clusters:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</code></pre></div></div> <blockquote> <p><strong>Output:</strong></p> </blockquote> <p><img src="/static/assets/img/blog/kmeanexample.png" width="30%" /></p> <hr /> <h2 id="gaussian-mixture-models"><strong>Gaussian Mixture Models</strong></h2> <p align="center"> <img src="/static/assets/img/blog/gmm.gif" width="50%" /></p> <p>Due to the <code class="highlighter-rouge">non-probabilistic</code> nature of k-means and its use of simple <code class="highlighter-rouge">distance-from-cluster-center</code> to assign cluster membership leads to <code class="highlighter-rouge">poor</code> performance for many <code class="highlighter-rouge">real-world</code> situations. As we can see, the mode of clustering by using k-means <code class="highlighter-rouge">must</code> be a <code class="highlighter-rouge">circle</code>, and it doesn’t have built-in method to calculate oblong or elliptical clusters. Hence, the <code class="highlighter-rouge">gaussian mixture model</code> is established. The <code class="highlighter-rouge">gaussian mixture model (GMM)</code> attempts to find a mixture of multidimensional <code class="highlighter-rouge">gaussian probability distributions</code> to simulate any input data set.</p> <blockquote> <p><strong>Pseudocode:</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">choose</span> <span class="n">starting</span> <span class="n">guesses</span> <span class="k">for</span> <span class="n">the</span> <span class="n">location</span> <span class="ow">and</span> <span class="n">shape</span>
<span class="k">while</span> <span class="ow">not</span> <span class="n">converges</span><span class="p">:</span>
    <span class="c"># E-step</span>
    <span class="k">for</span> <span class="n">each</span> <span class="n">data</span> <span class="n">point</span><span class="p">:</span>
        <span class="n">find</span> <span class="n">weights</span> <span class="n">encoding</span> <span class="n">the</span> <span class="n">probability</span> <span class="n">of</span> <span class="n">membership</span> <span class="ow">in</span> <span class="n">each</span> <span class="n">cluster</span>
    <span class="c"># M-step</span>
    <span class="k">for</span> <span class="n">each</span> <span class="n">cluster</span>
        <span class="n">update</span> <span class="n">its</span> <span class="n">location</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="ow">and</span> <span class="n">shape</span> <span class="n">based</span> <span class="n">on</span> <span class="nb">all</span> <span class="n">data</span> <span class="n">points</span><span class="p">,</span> <span class="n">making</span> <span class="n">use</span> <span class="n">of</span> <span class="n">the</span> <span class="n">weights</span>
</code></pre></div></div> <blockquote> <p><strong>Code Example with Scrit-Learn</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GMM</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c"># input data, containing 4 blobs</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.40</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c"># initialize gmm and train it</span>
<span class="n">gmm</span> <span class="o">=</span> <span class="n">GMM</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c">#predict result</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p><strong>Output:</strong></p> </blockquote> <p><img src="/static/assets/img/blog/gmmout.png" width="30%" /></p> <hr /> <h2 id="silhouette-analysis"><strong>Silhouette Analysis</strong></h2> <p>If the data is naturally organized into a number of distinct clusters, then it is easy to visually examine it and draw some inferences. But this is <code class="highlighter-rouge">rarely</code> the case in the real world. The data in the real world is <code class="highlighter-rouge">huge and messy</code>, so we need a way to quantify the <code class="highlighter-rouge">quality</code> of the clustering.</p> <p>Silhouette is a way to evaluate the <code class="highlighter-rouge">clustering quality</code>. The <code class="highlighter-rouge">range</code> of the Silhouette Score is between <code class="highlighter-rouge">-1 and 1</code></p> <blockquote> <p><code class="highlighter-rouge">Formula</code>: $\Large\frac{silhouette score = (p - q)}{ max(p, q)}$</p> <ul> <li><em><code class="highlighter-rouge">p</code> is the <code class="highlighter-rouge">mean distance</code> to the points in the <code class="highlighter-rouge">nearest</code> cluster that the data point is not a part of</em></li> <li><em><code class="highlighter-rouge">q</code> is the <code class="highlighter-rouge">mean intra-cluster distance</code> to <code class="highlighter-rouge">all</code> the points in its <code class="highlighter-rouge">own</code> cluster.</em></li> </ul> </blockquote> <p align="center"> <img src="/static/assets/img/blog/silhouette_analysis.png" width="70%" /></p> <blockquote> <p><strong>Code Example with Scrit-Learn</strong></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c"># input data, containing 4 blobs</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.40</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c"># Initialize variables</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

<span class="c"># Iterate through the defined range</span>
<span class="k">for</span> <span class="n">num_clusters</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
    <span class="c"># Train the KMeans clustering model</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="s">'k-means++'</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> 
                <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span> <span class="n">sample_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Number of clusters ="</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Silhouette score ="</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
                    
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

<span class="c"># Plot silhouette scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span>
<span class="n">align</span><span class="o">=</span><span class="s">'center'</span><span class="p">)</span>

<span class="c"># Extract best score and optimal number of clusters</span>
<span class="n">num_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="o">+</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Optimal number of clusters ='</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p><strong>Output:</strong></p> </blockquote> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of clusters = 2
Silhouette score = 0.5983028377054385

Number of clusters = 3
Silhouette score = 0.6735963463903952

Number of clusters = 4
Silhouette score = 0.7900520050938619

Number of clusters = 5
Silhouette score = 0.6829517395665077

Number of clusters = 6
Silhouette score = 0.563136216297564

Number of clusters = 7
Silhouette score = 0.4525060848311459

Number of clusters = 8
Silhouette score = 0.3264185389751767

Number of clusters = 9
Silhouette score = 0.3248083544292323

Optimal number of clusters = 4
</code></pre></div></div> <p><img src="/static/assets/img/blog/sstable.png" width="30%" /></p> <hr /> <blockquote> <p><strong>End –Cheng Gu</strong></p> </blockquote> <hr> <div class="row"> <div class="col-md-6"> <h5 style="display: inline;">Tags:</h5> <button class="btn btn-white btn-xs" type="button">Python</button> <button class="btn btn-white btn-xs" type="button">Ai</button> </div> <div class="col-md-6"> <div class="small text-right"> <div> </div> </div> </div> </div> <br> <div class="row"> <div class="col-lg-12"> <!-- donate --> <br> <!-- share --> <div class="a2a_kit a2a_kit_size_32 a2a_default_style"> <a class="a2a_dd" href="https://www.addtoany.com/share"></a> <a class="a2a_button_facebook"></a> <a class="a2a_button_twitter"></a> <a class="a2a_button_google_plus"></a> <a class="a2a_button_linkedin"></a> <a class="a2a_button_email"></a> <a class="a2a_button_wechat"></a> <a class="a2a_button_sina_weibo"></a> <a class="a2a_button_pocket"></a> </div> <script> var a2a_config = a2a_config || {}; a2a_config.color_main = "D7E5ED"; a2a_config.color_border = "AECADB"; a2a_config.color_link_text = "333333"; a2a_config.color_link_text_hover = "333333"; </script> <script async src="https://static.addtoany.com/menu/page.js"></script> <br> <!-- comment --> </div> </div> </div> </div> </div> </div> </div> <!-- Google analytics --> <!-- GrowingIO --> </body> </html>
