<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1 maximum-scale=1; minimum-scale=1; user-scalable=no;"> <meta name="author" content="ChengGu"> <meta name="baseurl" content=""> <title> Suzuka Site|Artificial Neural Network(ML) </title> <!-- favicon --> <link rel="shortcut icon" href="/static/assets/img/favicon.ico"> <!-- Main CSS --> <link href="/static/assets/app-20180125.min.css" rel="stylesheet"> <link href="/static/css/custom.css" rel="stylesheet"> <!-- Main Scripts --> <script src="/static/assets/app-20180125.min.js"></script> <script src="/static/assets/blog-20180125.min.js"></script> <!-- Google AdSense --> <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> <script> (adsbygoogle = window.adsbygoogle || []).push({ google_ad_client: "ca-pub-6196184668650108", enable_page_level_ads: true }); </script> </head> <body id="page-top" class="landing-page"> <div class="search-tool" style="position: fixed; top: 0px ; bottom: 0px; left: 0px; right: 0px; opacity: 0.95; background-color: #111111; z-index: 9999; display: none;"> <input type="text" class="form-control search-content" id="search-content" style="position: fixed; top: 60px" placeholder="Search Blog"> <div style="position: fixed; top: 16px; right: 16px; z-index: 9999;"> <img src="/static/assets/img/search/cb-close.png" id="close-btn"/> </div> </div> <div style="position: fixed; right: 16px; bottom: 20px; z-index: 9999;"> <img src="/static/assets/img/search/cb-search.png" id="search-btn" title="Double click Ctrl"/> </div> <div class="navbar-wrapper"> <nav class="navbar navbar-default navbar-fixed-top" role="navigation"> <div class="container"> <div class="navbar-header page-scroll"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/">Suzuka Site</a> </div> <div id="navbar" class="navbar-collapse collapse"> <ul class="nav navbar-nav navbar-right"> <li><a class="page-scroll" href="blog/"></a></li> <li> <a class="page-scroll" href="/blog/">Blog</a></li> <li> <a class="page-scroll" href="/unity/">Unity</a></li> <li> <a class="page-scroll" href="/ai/">AI</a></li> <li> <a class="page-scroll" href="/cg/">CG</a></li> <li> <a class="page-scroll" href="/math/">Math</a></li> <li> <a class="page-scroll" href="/data structure/">Data Structure</a></li> <li> <a class="page-scroll" href="/csharp/">C#</a></li> <li> <a class="page-scroll" href="/python/">Python</a></li> <li> <a class="page-scroll" href="/javascript/">JavaScript</a></li> <li> <a class="page-scroll" href="/game dev/">Game Dev</a></li> </ul> </div> </div> </nav> </div> <!--<link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css'>--> <!--<link rel="stylesheet" href="static/css/carousel_style.css">--> <!--<script src="static/js/carousel.js"></script>--> <div id="carouselHacked" class="carousel slide carousel-fade" data-ride="carousel"> <div class="carousel-inner" role="listbox"> <div class="item active"> <!-- Set background for slide in css --> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_1.jpg);" title="first banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_2.jpg);" title=""> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_3.jpg);" title="third banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_4.jpg);" title="fourth banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_5.jpg);" title="fifth banner image"> </div> </div> <div class="item"> <div class="header-back" style="background-image: url(/static/assets/img/landing/header_6.jpg);" title="sixth banner image"> </div> </div> </div> <!-- Controls --> <a class="left carousel-control" href="#carouselHacked" role="button" data-slide="prev"> <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span> <span class="sr-only">Previous</span> </a> <a class="right carousel-control" href="#carouselHacked" role="button" data-slide="next"> <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span> <span class="sr-only">Next</span> </a> </div> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true } }); </script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <div class="wrapper wrapper-content animated fadeInRight article"> <div class="row"> <div class="col-lg-10 col-lg-offset-1"> <div class="ibox"> <div class="ibox-content"> <div class="pull-right"> <a class="btn btn-white btn-xs" href="/python">Python</a> <a class="btn btn-white btn-xs" href="/ai">Ai</a> </div> <div class="text-center article-title"> <span class="text-muted"><i class="fa fa-clock-o"></i> 10 Mar 2019</span> <h1> Artificial Neural Network(ML) </h1> </div> <h1 id="what-is-artificial-neuron"><strong>What is Artificial Neuron?</strong></h1> <p>An <code class="highlighter-rouge">artificial neuron</code> is a mathematical function conceived as a model of biological neurons in our brains. Artificial neurons are elementary units in an artificial neural network (ANN). The artificial neuron receives one or more <code class="highlighter-rouge">inputs</code> and <code class="highlighter-rouge">sums</code> them to produce an <code class="highlighter-rouge">output</code>. Usually each input is separately <code class="highlighter-rouge">weighted</code>, and the sum is passed through a function known as an <code class="highlighter-rouge">activation function</code>.</p> <p align="center"> <img src="/static/assets/img/blog/ann.jpg" width="40%" /></p> <hr /> <h2 id="activation-functions"><strong>Activation Functions</strong></h2> <p>A <code class="highlighter-rouge">sigmoid</code> function is a mathematical function having acharacteristic “S” -shaped curve or sigmoid curve and generates outputs <code class="highlighter-rouge">between 0 and 1</code>. The sigmoid activation function is widely used in <code class="highlighter-rouge">binary classification</code>.</p> <p>An alternative to the sigmoid is the <code class="highlighter-rouge">hyperbolic tangent (Tan-h)</code> function. Like the sigmoid, the tan-h function is also sigmoidal(“S”-shaped), but instead outputs values that range <code class="highlighter-rouge">-1 to 1</code>.</p> <p>Most recent artificial neural networks use <code class="highlighter-rouge">rectified linear units (ReLU)</code> for the hidden layers. ReLU has output 0 if the input is less than 0, and raw output otherwise. That is, if the input is greater than 0, the output is equal to the input. <code class="highlighter-rouge">(output = max(0, input))</code></p> <p align="center"> <img src="/static/assets/img/blog/activatefunction.jpg" width="80%" /></p> <h2 id="the-xor-problem"><strong>The XOR Problem</strong></h2> <p>An XOR function should return <code class="highlighter-rouge">true</code> if two inputs are <code class="highlighter-rouge">not</code> equal ,else return <code class="highlighter-rouge">false</code>(Shown as below image):</p> <p align="center"> <img src="/static/assets/img/blog/xor.png" width="30%" /></p> <p>The <code class="highlighter-rouge">XOR</code> problem is a classic problem in ANN Research. It is the problem that there are no ways to using perceptron to predict the <code class="highlighter-rouge">True</code> outputs of XOR logic gate given two binary inputs, because XOR inputs are <code class="highlighter-rouge">not linearly separable</code>, and perceptron <code class="highlighter-rouge">only</code> works for <code class="highlighter-rouge">linear separation</code>.</p> <p align="center"> <img src="/static/assets/img/blog/xorp.gif" width="50%" /></p> <p>Therefore, duringing that time<code class="highlighter-rouge">(1969- 1986)</code>, it was “AI Winter” until the <code class="highlighter-rouge">MultiLayer Artificial Neural Networks</code> appear(1986).</p> <hr /> <h1 id="what-is-artificial-neural-networks"><strong>What is Artificial Neural Networks?</strong></h1> <p><code class="highlighter-rouge">Artificial Neural Networks(ANNs)</code> are collections of connected nodes made up of <code class="highlighter-rouge">artificial neurons(perceptron)</code>, providing a framework for different machine learning algorithms to work together and process complex data inputs. Such systems “learn” to perform tasks by considering examples, generally without being programmed with any task-specific rules.</p> <p align="center"> <img src="/static/assets/img/blog/ArtificialNeuralNetwork.jpg" width="70%" /></p> <p>The biggest significance of this architecture is capable of achieving <code class="highlighter-rouge">non-linear separation</code>(shown as below):</p> <p align="center"> <img src="/static/assets/img/blog/annc.png" width="50%" /></p> <hr /> <h1 id="forward-propagation-vs-back-propagation"><strong>Forward Propagation vs. Back Propagation</strong></h1> <p><code class="highlighter-rouge">Forward propagation</code> is process of <code class="highlighter-rouge">feeding</code> the Neural Network with a set of inputs and comparing the numerical value of the output to the expected output in order to compute the error function.</p> <p><code class="highlighter-rouge">Back propagation</code> is a method used in ANNs to <code class="highlighter-rouge">calculate the weights</code> to be used in the network. It is the backward propagation of errors through the network layers, since an error function is computed at the output. This technique is commonly used to train deep neural networks.</p> <p align="center"> <img src="/static/assets/img/blog/fbp.png" width="50%" /></p> <h1 id="feedforward-networks-vs-recurrent-neural-networks"><strong>Feedforward Networks vs. Recurrent Neural Networks</strong></h1> <p>The simplest type of ANN is considered a <code class="highlighter-rouge">Feedforward Neural Network</code>, such as perceptron. This means that the information moves only in <code class="highlighter-rouge">forward direction</code> from the input nodes, through the hidden nodes to the outputs. A feedforward network has no notion of order in time, and the <code class="highlighter-rouge">only</code> input it considers is the current example it has been exposed to.</p> <p><strong>Recurrent Neural Networks (RNNs)</strong> are structured in such a way as to take as their input not just the current input example they see, but also what they have perceived previously in time. Recurrent networks are distinguished from feedforward networks by that <code class="highlighter-rouge">feedback loop</code> connected to their past decisions. It is often said that recurrent networks have <code class="highlighter-rouge">memory</code></p> <p align="center"> <img src="/static/assets/img/blog/fowardvsbackward.jpg" width="50%" /></p> <h1 id="recurrent-neural-networksrnn-vs-long-short-term-memorylstm"><strong>Recurrent Neural Networks(RNN) vs. Long Short-Term Memory(LSTM)</strong></h1> <p>By the early 1990s, the <code class="highlighter-rouge">Vanishing Gradient Problem</code> emerged as a major <code class="highlighter-rouge">obstacle</code> to <code class="highlighter-rouge">RNN</code> performance. Because the information flowing through neural networks passes through many stages of multiplication, the outputs are susceptible to <code class="highlighter-rouge">"Vanishing"</code> (gradually decreasing) or <code class="highlighter-rouge">"Exploding"</code> (exponentially increasing).</p> <p>In the mid-90s, a variation of RNN called <code class="highlighter-rouge">Long Short-Term Memory (LSTM)</code>, was proposed as a <code class="highlighter-rouge">solution</code> to the <code class="highlighter-rouge">vanishing gradient problem</code>. LSTMs help preserve the error that can be backpropagated through time and layers, allowing RNNs to continue to learn <code class="highlighter-rouge">over</code> many time steps (over 1000).</p> <p align="center"> <img src="/static/assets/img/blog/rnn-vs-lstm.jpg" width="50%" /></p> <hr /> <blockquote> <p><strong>End –Cheng Gu</strong></p> </blockquote> <hr> <div class="row"> <div class="col-md-6"> <h5 style="display: inline;">Tags:</h5> <button class="btn btn-white btn-xs" type="button">Python</button> <button class="btn btn-white btn-xs" type="button">Ai</button> </div> <div class="col-md-6"> <div class="small text-right"> <div> </div> </div> </div> </div> <br> <div class="row"> <div class="col-lg-12"> <!-- donate --> <br> <!-- share --> <div class="a2a_kit a2a_kit_size_32 a2a_default_style"> <a class="a2a_dd" href="https://www.addtoany.com/share"></a> <a class="a2a_button_facebook"></a> <a class="a2a_button_twitter"></a> <a class="a2a_button_google_plus"></a> <a class="a2a_button_linkedin"></a> <a class="a2a_button_email"></a> <a class="a2a_button_wechat"></a> <a class="a2a_button_sina_weibo"></a> <a class="a2a_button_pocket"></a> </div> <script> var a2a_config = a2a_config || {}; a2a_config.color_main = "D7E5ED"; a2a_config.color_border = "AECADB"; a2a_config.color_link_text = "333333"; a2a_config.color_link_text_hover = "333333"; </script> <script async src="https://static.addtoany.com/menu/page.js"></script> <br> <!-- comment --> </div> </div> </div> </div> </div> </div> </div> <!-- Google analytics --> <!-- GrowingIO --> </body> </html>
